\relax 
\providecommand{\transparent@use}[1]{}
\bibstyle{biblatex}
\bibdata{Jacobs_Quantification_HPT-blx,HPT}
\citation{biblatex-control}
\abx@aux@refcontext{nyvt/global//global/global}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{skinner_meaning_1969}
\abx@aux@cite{0}{skinner_meaning_1969}
\abx@aux@segm{0}{0}{skinner_meaning_1969}
\citation{pocock_virtue_1985}
\abx@aux@cite{0}{pocock_virtue_1985}
\abx@aux@segm{0}{0}{pocock_virtue_1985}
\citation{pocock_virtue_1985}
\abx@aux@cite{0}{pocock_virtue_1985}
\abx@aux@segm{0}{0}{pocock_virtue_1985}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{2}{Introduction}{section.1}{}}
\citation{tully_meaning_1988}
\abx@aux@cite{0}{tully_meaning_1988}
\abx@aux@segm{0}{0}{tully_meaning_1988}
\citation{skinner_return_1990}
\abx@aux@cite{0}{skinner_return_1990}
\abx@aux@segm{0}{0}{skinner_return_1990}
\citation{tully_meaning_1988}
\abx@aux@cite{0}{tully_meaning_1988}
\abx@aux@segm{0}{0}{tully_meaning_1988}
\citation{skinner_foundations_1978a}
\abx@aux@cite{0}{skinner_foundations_1978a}
\abx@aux@segm{0}{0}{skinner_foundations_1978a}
\citation{london_reimagining_2016}
\abx@aux@cite{0}{london_reimagining_2016}
\abx@aux@segm{0}{0}{london_reimagining_2016}
\citation{scott_schools_2001}
\abx@aux@cite{0}{scott_schools_2001}
\abx@aux@segm{0}{0}{scott_schools_2001}
\citation{skinner_foundations_1978b}
\abx@aux@cite{0}{skinner_foundations_1978b}
\abx@aux@segm{0}{0}{skinner_foundations_1978b}
\citation{pocock_machiavellian_1975}
\abx@aux@cite{0}{pocock_machiavellian_1975}
\abx@aux@segm{0}{0}{pocock_machiavellian_1975}
\citation{pocock_virtue_1985}
\abx@aux@cite{0}{pocock_virtue_1985}
\abx@aux@segm{0}{0}{pocock_virtue_1985}
\citation{wevers_digital_2020}
\abx@aux@cite{0}{wevers_digital_2020}
\abx@aux@segm{0}{0}{wevers_digital_2020}
\citation{feuer_north_1963}
\abx@aux@cite{0}{feuer_north_1963}
\abx@aux@segm{0}{0}{feuer_north_1963}
\citation{gourevitch_slavery_2015}
\abx@aux@cite{0}{gourevitch_slavery_2015}
\abx@aux@segm{0}{0}{gourevitch_slavery_2015}
\citation{comrie_languages_1981}
\abx@aux@cite{0}{comrie_languages_1981}
\abx@aux@segm{0}{0}{comrie_languages_1981}
\citation{jacobs_quantifying_2021}
\abx@aux@cite{0}{jacobs_quantifying_2021}
\abx@aux@segm{0}{0}{jacobs_quantifying_2021}
\citation{feng_languageagnostic_2022}
\abx@aux@cite{0}{feng_languageagnostic_2022}
\abx@aux@segm{0}{0}{feng_languageagnostic_2022}
\citation{yang_languageagnostic_2020}
\abx@aux@cite{0}{yang_languageagnostic_2020}
\abx@aux@segm{0}{0}{yang_languageagnostic_2020}
\citation{heffernan_bitext_2022}
\abx@aux@cite{0}{heffernan_bitext_2022}
\abx@aux@segm{0}{0}{heffernan_bitext_2022}
\citation{heffernan_bitext_2022}
\abx@aux@cite{0}{heffernan_bitext_2022}
\abx@aux@segm{0}{0}{heffernan_bitext_2022}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{10}{section.2}\protected@file@percent }
\newlabel{sec:background}{{2}{10}{Background}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Word Embeddings: The Geometry of Political Thought}{10}{subsection.2.1}\protected@file@percent }
\newlabel{sec:embeddings}{{2.1}{10}{Word Embeddings: The Geometry of Political Thought}{subsection.2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces An intuitive schema for guessing what section of the New York Times a particular article was published in, using only the text of the article (i.e., by counting the number of occurrences of each keyword in each article)\relax }}{10}{table.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:nytimes}{{1}{10}{An intuitive schema for guessing what section of the New York Times a particular article was published in, using only the text of the article (i.e., by counting the number of occurrences of each keyword in each article)\relax }{table.caption.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The per-section accuracy scores for our word-count-based division of the \textit  {New York Times} article corpus.\relax }}{11}{table.caption.3}\protected@file@percent }
\newlabel{tab:nytimes-sections}{{2}{11}{The per-section accuracy scores for our word-count-based division of the \textit {New York Times} article corpus.\relax }{table.caption.3}{}}
\citation{firth_papers_1957}
\abx@aux@cite{0}{firth_papers_1957}
\abx@aux@segm{0}{0}{firth_papers_1957}
\citation{skinner_meaning_1969}
\abx@aux@cite{0}{skinner_meaning_1969}
\abx@aux@segm{0}{0}{skinner_meaning_1969}
\citation{pocock_political_2009}
\abx@aux@cite{0}{pocock_political_2009}
\abx@aux@segm{0}{0}{pocock_political_2009}
\citation{wittgenstein_philosophical_1953}
\abx@aux@cite{0}{wittgenstein_philosophical_1953}
\abx@aux@segm{0}{0}{wittgenstein_philosophical_1953}
\citation{austin_how_1962}
\abx@aux@cite{0}{austin_how_1962}
\abx@aux@segm{0}{0}{austin_how_1962}
\citation{dummett_frege_1973}
\abx@aux@cite{0}{dummett_frege_1973}
\abx@aux@segm{0}{0}{dummett_frege_1973}
\citation{skinner_visions_2012}
\abx@aux@cite{0}{skinner_visions_2012}
\abx@aux@segm{0}{0}{skinner_visions_2012}
\citation{skinner_visions_2012}
\abx@aux@cite{0}{skinner_visions_2012}
\abx@aux@segm{0}{0}{skinner_visions_2012}
\citation{skinner_visions_2012}
\abx@aux@cite{0}{skinner_visions_2012}
\abx@aux@segm{0}{0}{skinner_visions_2012}
\citation{bevir_are_1994}
\abx@aux@cite{0}{bevir_are_1994}
\abx@aux@segm{0}{0}{bevir_are_1994}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}The Historiography of Political Thought}{12}{subsection.2.2}\protected@file@percent }
\newlabel{sec:methods-hpt}{{2.2}{12}{The Historiography of Political Thought}{subsection.2.2}{}}
\citation{skinner_liberty_1998}
\abx@aux@cite{0}{skinner_liberty_1998}
\abx@aux@segm{0}{0}{skinner_liberty_1998}
\citation{strauss_what_1959}
\abx@aux@cite{0}{strauss_what_1959}
\abx@aux@segm{0}{0}{strauss_what_1959}
\citation{plamenatz_man_1963}
\abx@aux@cite{0}{plamenatz_man_1963}
\abx@aux@segm{0}{0}{plamenatz_man_1963}
\citation{skinner_meaning_1969}
\abx@aux@cite{0}{skinner_meaning_1969}
\abx@aux@segm{0}{0}{skinner_meaning_1969}
\citation{skinner_visions_2012}
\abx@aux@cite{0}{skinner_visions_2012}
\abx@aux@segm{0}{0}{skinner_visions_2012}
\citation{wood_citizens_2008}
\abx@aux@cite{0}{wood_citizens_2008}
\abx@aux@segm{0}{0}{wood_citizens_2008}
\citation{ash_ideas_2017}
\abx@aux@cite{0}{ash_ideas_2017}
\abx@aux@segm{0}{0}{ash_ideas_2017}
\citation{shapiro_selective_1987}
\abx@aux@cite{0}{shapiro_selective_1987}
\abx@aux@segm{0}{0}{shapiro_selective_1987}
\citation{ashcraft_locke_1986}
\abx@aux@cite{0}{ashcraft_locke_1986}
\abx@aux@segm{0}{0}{ashcraft_locke_1986}
\citation{pocock_political_2009}
\abx@aux@cite{0}{pocock_political_2009}
\abx@aux@segm{0}{0}{pocock_political_2009}
\citation{darnton_revolution_1989}
\abx@aux@cite{0}{darnton_revolution_1989}
\abx@aux@segm{0}{0}{darnton_revolution_1989}
\citation{darnton_revolution_1989}
\abx@aux@cite{0}{darnton_revolution_1989}
\abx@aux@segm{0}{0}{darnton_revolution_1989}
\citation{goodman_republic_1996}
\abx@aux@cite{0}{goodman_republic_1996}
\abx@aux@segm{0}{0}{goodman_republic_1996}
\citation{pocock_political_2009}
\abx@aux@cite{0}{pocock_political_2009}
\abx@aux@segm{0}{0}{pocock_political_2009}
\citation{rawls_outline_1951}
\abx@aux@cite{0}{rawls_outline_1951}
\abx@aux@segm{0}{0}{rawls_outline_1951}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}From Computational Linguistics to the Cambridge School and Back}{18}{subsection.2.3}\protected@file@percent }
\newlabel{sec:methods-ling-cambridge}{{2.3}{18}{From Computational Linguistics to the Cambridge School and Back}{subsection.2.3}{}}
\citation{wittgenstein_philosophical_1953}
\abx@aux@cite{0}{wittgenstein_philosophical_1953}
\abx@aux@segm{0}{0}{wittgenstein_philosophical_1953}
\citation{saussure_course_1916}
\abx@aux@cite{0}{saussure_course_1916}
\abx@aux@segm{0}{0}{saussure_course_1916}
\citation{austin_how_1962}
\abx@aux@cite{0}{austin_how_1962}
\abx@aux@segm{0}{0}{austin_how_1962}
\citation{wittgenstein_tractatus_1921}
\abx@aux@cite{0}{wittgenstein_tractatus_1921}
\abx@aux@segm{0}{0}{wittgenstein_tractatus_1921}
\citation{gregoire_geste_1948}
\abx@aux@cite{0}{gregoire_geste_1948}
\abx@aux@segm{0}{0}{gregoire_geste_1948}
\citation{jakobson_linguistics_1960}
\abx@aux@cite{0}{jakobson_linguistics_1960}
\abx@aux@segm{0}{0}{jakobson_linguistics_1960}
\citation{jakobson_child_1941}
\abx@aux@cite{0}{jakobson_child_1941}
\abx@aux@segm{0}{0}{jakobson_child_1941}
\citation{jakobson_linguistics_1957}
\abx@aux@cite{0}{jakobson_linguistics_1957}
\abx@aux@segm{0}{0}{jakobson_linguistics_1957}
\citation{lazaridou_this_2014}
\abx@aux@cite{0}{lazaridou_this_2014}
\abx@aux@segm{0}{0}{lazaridou_this_2014}
\citation{quine_word_1960}
\abx@aux@cite{0}{quine_word_1960}
\abx@aux@segm{0}{0}{quine_word_1960}
\newlabel{fig:nytimes-pgm1}{{1a}{23}{``A \entity {British} official, speaking anonymously because of the delicacy of the diplomatic exchanges between \entity {London} and \entity {Tehran}...''\relax }{figure.caption.4}{}}
\newlabel{sub@fig:nytimes-pgm1}{{a}{23}{``A \entity {British} official, speaking anonymously because of the delicacy of the diplomatic exchanges between \entity {London} and \entity {Tehran}...''\relax }{figure.caption.4}{}}
\newlabel{fig:nytimes-pgm2}{{1b}{23}{``The \entity {Bush} administration said Thursday that the release of 15 \entity {British} sailors and marines held by \entity {Iran} for two weeks created no new openings in dealing with \entity {Tehran}...''\relax }{figure.caption.4}{}}
\newlabel{sub@fig:nytimes-pgm2}{{b}{23}{``The \entity {Bush} administration said Thursday that the release of 15 \entity {British} sailors and marines held by \entity {Iran} for two weeks created no new openings in dealing with \entity {Tehran}...''\relax }{figure.caption.4}{}}
\newlabel{fig:nytimes-pgm3}{{1c}{23}{``By deceiving the nuclear agency about its activities, President \entity {Bush} and \entity {British}, French and German officials say, \entity {Iran} has given up whatever treaty rights it once enjoyed.''\relax }{figure.caption.4}{}}
\newlabel{sub@fig:nytimes-pgm3}{{c}{23}{``By deceiving the nuclear agency about its activities, President \entity {Bush} and \entity {British}, French and German officials say, \entity {Iran} has given up whatever treaty rights it once enjoyed.''\relax }{figure.caption.4}{}}
\newlabel{fig:nytimes-pgm4}{{1d}{23}{``Asserting \entity {Washington}'s determination to protect Japan and South Korea, its principal allies in the region, Mr. \entity {Bush} said the \entity {United States} `will meet the full range of our deterrent and security commitments.'{}''\relax }{figure.caption.4}{}}
\newlabel{sub@fig:nytimes-pgm4}{{d}{23}{``Asserting \entity {Washington}'s determination to protect Japan and South Korea, its principal allies in the region, Mr. \entity {Bush} said the \entity {United States} `will meet the full range of our deterrent and security commitments.'{}''\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Graphical models of the relationships which context-sensitive text-analysis algorithms can infer from sentences (1) through (4) above.\relax }}{23}{figure.caption.4}\protected@file@percent }
\newlabel{fig:nytimes-pgm14}{{1}{23}{Graphical models of the relationships which context-sensitive text-analysis algorithms can infer from sentences (1) through (4) above.\relax }{figure.caption.4}{}}
\newlabel{fig:nytimes-pgm5}{{2a}{24}{The systematic merging of the networks in Figures \ref {fig:nytimes-pgm1} and \ref {fig:nytimes-pgm2}.\relax }{figure.caption.5}{}}
\newlabel{sub@fig:nytimes-pgm5}{{a}{24}{The systematic merging of the networks in Figures \ref {fig:nytimes-pgm1} and \ref {fig:nytimes-pgm2}.\relax }{figure.caption.5}{}}
\newlabel{fig:nytimes-pgm6}{{2b}{24}{The network formed by incorporating the information in Figure \ref {fig:nytimes-pgm3} into the network of panel (a).\relax }{figure.caption.5}{}}
\newlabel{sub@fig:nytimes-pgm6}{{b}{24}{The network formed by incorporating the information in Figure \ref {fig:nytimes-pgm3} into the network of panel (a).\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces An illustration of how, after constructing the individual-sentence context networks in Figure \ref {fig:nytimes-pgm14}, the algorithm can systematically merge the information across sentences, eventually producing the final corpus-wide network shown in Figure \ref {fig:nytimes-pgmfinal}.\relax }}{24}{figure.caption.5}\protected@file@percent }
\newlabel{fig:nytimes-pgm57}{{2}{24}{An illustration of how, after constructing the individual-sentence context networks in Figure \ref {fig:nytimes-pgm14}, the algorithm can systematically merge the information across sentences, eventually producing the final corpus-wide network shown in Figure \ref {fig:nytimes-pgmfinal}.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The final corpus-wide contextual network, combining all information from the individual networks in Figure \ref {fig:nytimes-pgm14} (edge labels omitted for clarity).\relax }}{24}{figure.caption.6}\protected@file@percent }
\newlabel{fig:nytimes-pgmfinal}{{3}{24}{The final corpus-wide contextual network, combining all information from the individual networks in Figure \ref {fig:nytimes-pgm14} (edge labels omitted for clarity).\relax }{figure.caption.6}{}}
\citation{reimers_sentencebert_2019}
\abx@aux@cite{0}{reimers_sentencebert_2019}
\abx@aux@segm{0}{0}{reimers_sentencebert_2019}
\citation{beltagy_longformer_2020}
\abx@aux@cite{0}{beltagy_longformer_2020}
\abx@aux@segm{0}{0}{beltagy_longformer_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A visualization of the ``analogical math'' which can be performed within word embedding spaces, due to their ability to capture multiple \textit  {types} of word-word relationships in the form of distances ranging over multiple dimensions: entity vectors are typeset in fixed-width font ($\texttt  {Entity}$), while relational vectors are typeset in serif font ($\textsf  {Relation}$). The vector from $\texttt  {Russia}$ to $\texttt  {U.S.}$, a relational vector, is typeset in fixed-width font only to illustrate its mathematical form (i.e., that it is computed via the subtraction two entity vectors).\relax }}{26}{figure.caption.7}\protected@file@percent }
\newlabel{fig:nyt-vectors}{{4}{26}{A visualization of the ``analogical math'' which can be performed within word embedding spaces, due to their ability to capture multiple \textit {types} of word-word relationships in the form of distances ranging over multiple dimensions: entity vectors are typeset in fixed-width font ($\entvec {Entity}$), while relational vectors are typeset in serif font ($\relvec {Relation}$). The vector from $\entvec {Russia}$ to $\entvec {U.S.}$, a relational vector, is typeset in fixed-width font only to illustrate its mathematical form (i.e., that it is computed via the subtraction two entity vectors).\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Models of Meaning and Context}{26}{section.3}\protected@file@percent }
\newlabel{sec:meaning-context}{{3}{26}{Models of Meaning and Context}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Constructing Contextual Fields}{26}{subsection.3.1}\protected@file@percent }
\newlabel{sec:contextual-fields}{{3.1}{26}{Constructing Contextual Fields}{subsection.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Visualizing three of the potential pathways by which one can move from the $\texttt  {Russia}$ to the $\texttt  {Kyiv}$ vectors.\relax }}{27}{figure.caption.8}\protected@file@percent }
\newlabel{fig:nyt-paths}{{5}{27}{Visualizing three of the potential pathways by which one can move from the $\texttt {Russia}$ to the $\texttt {Kyiv}$ vectors.\relax }{figure.caption.8}{}}
\citation{chi_finding_2020}
\abx@aux@cite{0}{chi_finding_2020}
\abx@aux@segm{0}{0}{chi_finding_2020}
\citation{chi_finding_2020}
\abx@aux@cite{0}{chi_finding_2020}
\abx@aux@segm{0}{0}{chi_finding_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The word-level linguistic intuitions which, by constructing an appropriate geometric space, can be quantitatively measured by way of the Cosine Similarity metric: (a) On the left, \texttt  {France} and \texttt  {Italy} are quite similar, so that $\theta $ is close to $0^\circ $, and $\cos (\theta )$ is close to $1$. (b) On the right, \texttt  {Ball} and \texttt  {Crocodile} are not similar, so that $\theta $ is close to $90^\circ $, and $\cos (\theta )$ is close to $0$.\relax }}{28}{figure.caption.9}\protected@file@percent }
\newlabel{fig:cosine-sim}{{6}{28}{The word-level linguistic intuitions which, by constructing an appropriate geometric space, can be quantitatively measured by way of the Cosine Similarity metric: (a) On the left, \entity {France} and \entity {Italy} are quite similar, so that $\theta $ is close to $0^\circ $, and $\cos (\theta )$ is close to $1$. (b) On the right, \entity {Ball} and \entity {Crocodile} are not similar, so that $\theta $ is close to $90^\circ $, and $\cos (\theta )$ is close to $0$.\relax }{figure.caption.9}{}}
\citation{kozlowski_geometry_2019}
\abx@aux@cite{0}{kozlowski_geometry_2019}
\abx@aux@segm{0}{0}{kozlowski_geometry_2019}
\citation{kozlowski_geometry_2019}
\abx@aux@cite{0}{kozlowski_geometry_2019}
\abx@aux@segm{0}{0}{kozlowski_geometry_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces An example of the higher-level properties of language which naturally emerge when an embedding algorithm computes \textit  {word-level} contextual-semantic similarities (that is, moves the points for words which occur in similar contexts closer together) across a large corpus of text from many different languages. (From \blx@tocontentsinit {0}\cite {chi_finding_2020}, Figure 6)\relax }}{29}{figure.caption.10}\protected@file@percent }
\newlabel{fig:xlang-embeddings}{{7}{29}{An example of the higher-level properties of language which naturally emerge when an embedding algorithm computes \textit {word-level} contextual-semantic similarities (that is, moves the points for words which occur in similar contexts closer together) across a large corpus of text from many different languages. (From \cite {chi_finding_2020}, Figure 6)\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The mathematical operation (dimensionality reduction) by which we compress the \textit  {full} set of word-context information in Hobbes' \textit  {Leviathan} (the matrix on the left) into a smaller matrix of two-dimensional vectors (the rows in the right-side matrix) which best preserve contextual similarity. That is, similar rows in the left-side matrix will be mapped to close-by points in 2D space, with $(x,y)$ coordinates as given in the right-side matrix.\relax }}{30}{figure.caption.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces An example of the matrix decomposition procedure that word embedding algorithms implement, to solve the problem of \textit  {retaining} information about word-context relationships while \textit  {reducing} the $M$-dimensional representations of each word down to 3 dimensions. (Example adapted from \blx@tocontentsinit {0}\cite {kozlowski_geometry_2019}, Figure 1)\relax }}{30}{figure.caption.12}\protected@file@percent }
\newlabel{fig:kozlowski-decomposition}{{9}{30}{An example of the matrix decomposition procedure that word embedding algorithms implement, to solve the problem of \textit {retaining} information about word-context relationships while \textit {reducing} the $M$-dimensional representations of each word down to 3 dimensions. (Example adapted from \cite {kozlowski_geometry_2019}, Figure 1)\relax }{figure.caption.12}{}}
\citation{mosteller_inference_1964}
\abx@aux@cite{0}{mosteller_inference_1964}
\abx@aux@segm{0}{0}{mosteller_inference_1964}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces A plot of the 3-dimensional word representations in Figure \ref {fig:kozlowski-decomposition}.\relax }}{31}{figure.caption.13}\protected@file@percent }
\newlabel{fig:geometry-td}{{10}{31}{A plot of the 3-dimensional word representations in Figure \ref {fig:kozlowski-decomposition}.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The Word-Context Matrix for the four-sentence Green Eggs and Ham corpus, along with the two-dimensional embeddings computed for each word.\relax }}{32}{figure.caption.14}\protected@file@percent }
\newlabel{fig:eggs-matrix}{{11}{32}{The Word-Context Matrix for the four-sentence Green Eggs and Ham corpus, along with the two-dimensional embeddings computed for each word.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces A plot of the two-dimensional vectors generated for the 8 unique words in the Green Eggs and Ham corpus.\relax }}{32}{figure.caption.15}\protected@file@percent }
\newlabel{fig:eggs-plot}{{12}{32}{A plot of the two-dimensional vectors generated for the 8 unique words in the Green Eggs and Ham corpus.\relax }{figure.caption.15}{}}
\citation{jurafsky_language_2014}
\abx@aux@cite{0}{jurafsky_language_2014}
\abx@aux@segm{0}{0}{jurafsky_language_2014}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The same points as in Figure \ref {fig:eggs-plot}, but rotated clockwise so that the ``love'' vector is aligned with the $x$-axis.\relax }}{33}{figure.caption.16}\protected@file@percent }
\newlabel{fig:eggs-plot-rotated}{{13}{33}{The same points as in Figure \ref {fig:eggs-plot}, but rotated clockwise so that the ``love'' vector is aligned with the $x$-axis.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The same points as in Figures \ref {fig:eggs-plot} and \ref {fig:eggs-plot-rotated}, but this time rotated and rescaled so that the vector from ``cats'' to ``dogs'' now serves as our $x$-axis.\relax }}{34}{figure.caption.17}\protected@file@percent }
\newlabel{fig:eggs-plot-orthogonal}{{14}{34}{The same points as in Figures \ref {fig:eggs-plot} and \ref {fig:eggs-plot-rotated}, but this time rotated and rescaled so that the vector from ``cats'' to ``dogs'' now serves as our $x$-axis.\relax }{figure.caption.17}{}}
\citation{tully_meaning_1988}
\abx@aux@cite{0}{tully_meaning_1988}
\abx@aux@segm{0}{0}{tully_meaning_1988}
\citation{parekh_history_1973}
\abx@aux@cite{0}{parekh_history_1973}
\abx@aux@segm{0}{0}{parekh_history_1973}
\citation{parekh_history_1973}
\abx@aux@cite{0}{parekh_history_1973}
\abx@aux@segm{0}{0}{parekh_history_1973}
\citation{skinner_hobbes_2008}
\abx@aux@cite{0}{skinner_hobbes_2008}
\abx@aux@segm{0}{0}{skinner_hobbes_2008}
\citation{mikolov_distributed_2013}
\abx@aux@cite{0}{mikolov_distributed_2013}
\abx@aux@segm{0}{0}{mikolov_distributed_2013}
\citation{kozlowski_geometry_2019}
\abx@aux@cite{0}{kozlowski_geometry_2019}
\abx@aux@segm{0}{0}{kozlowski_geometry_2019}
\citation{rheault_word_2020}
\abx@aux@cite{0}{rheault_word_2020}
\abx@aux@segm{0}{0}{rheault_word_2020}
\citation{ash_ideas_2017}
\abx@aux@cite{0}{ash_ideas_2017}
\abx@aux@segm{0}{0}{ash_ideas_2017}
\citation{barron_individuals_2018}
\abx@aux@cite{0}{barron_individuals_2018}
\abx@aux@segm{0}{0}{barron_individuals_2018}
\citation{devlin_bert_2019}
\abx@aux@cite{0}{devlin_bert_2019}
\abx@aux@segm{0}{0}{devlin_bert_2019}
\citation{pocock_virtue_1985}
\abx@aux@cite{0}{pocock_virtue_1985}
\abx@aux@segm{0}{0}{pocock_virtue_1985}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Visualization of a 2D embedding space generated from the English text of Hobbes' \textit  {Leviathan}.\relax }}{37}{figure.caption.18}\protected@file@percent }
\newlabel{fig:lev-embeddings}{{15}{37}{Visualization of a 2D embedding space generated from the English text of Hobbes' \textit {Leviathan}.\relax }{figure.caption.18}{}}
\citation{marx_herr_1860}
\abx@aux@cite{0}{marx_herr_1860}
\abx@aux@segm{0}{0}{marx_herr_1860}
\citation{rose_reading_1978}
\abx@aux@cite{0}{rose_reading_1978}
\abx@aux@segm{0}{0}{rose_reading_1978}
\citation{prawer_karl_1976}
\abx@aux@cite{0}{prawer_karl_1976}
\abx@aux@segm{0}{0}{prawer_karl_1976}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces A visualization of \texttt  {BERT}{}'s ability to compute numeric representations of the same word in multiple different contexts.\relax }}{39}{figure.caption.19}\protected@file@percent }
\newlabel{fig:bert-nobert}{{16}{39}{A visualization of \BERT {}'s ability to compute numeric representations of the same word in multiple different contexts.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Visualizing Contextual Fields}{39}{subsection.3.2}\protected@file@percent }
\newlabel{sec:methods-visualizing}{{3.2}{39}{Visualizing Contextual Fields}{subsection.3.2}{}}
\citation{dokmanic_euclidean_2015}
\abx@aux@cite{0}{dokmanic_euclidean_2015}
\abx@aux@segm{0}{0}{dokmanic_euclidean_2015}
\citation{vendruscolo_recovery_1997}
\abx@aux@cite{0}{vendruscolo_recovery_1997}
\abx@aux@segm{0}{0}{vendruscolo_recovery_1997}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces A case where the information about the corpus (the Word-Context Matrix on the left side) does not have sufficient statistical power to allow estimation of the word and context vectors (the matrices on the right side). At a high level, the algorithm is unlikely to be able to draw meaningful estimates for 7,680 parameters---the 3,840 entries in the word vectors matrix (the $u$ parameters), plus another 3,840 entries (not labeled) in the context vectors matrix $V$---using only 25 input data points. Looking more closely at the \textit  {structure} of the input data, we also see that it has no information from which to infer word 4's context-sensitive relation to other words, as it appears in only one context which is not shared by any other word in the corpus.\relax }}{41}{figure.caption.20}\protected@file@percent }
\newlabel{fig:decomposition-bad}{{17}{41}{A case where the information about the corpus (the Word-Context Matrix on the left side) does not have sufficient statistical power to allow estimation of the word and context vectors (the matrices on the right side). At a high level, the algorithm is unlikely to be able to draw meaningful estimates for 7,680 parameters---the 3,840 entries in the word vectors matrix (the $u$ parameters), plus another 3,840 entries (not labeled) in the context vectors matrix $V$---using only 25 input data points. Looking more closely at the \textit {structure} of the input data, we also see that it has no information from which to infer word 4's context-sensitive relation to other words, as it appears in only one context which is not shared by any other word in the corpus.\relax }{figure.caption.20}{}}
\citation{yetman_background_1967}
\abx@aux@cite{0}{yetman_background_1967}
\abx@aux@segm{0}{0}{yetman_background_1967}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces 100 randomly-generated points in 2D space, showing potential projections of these points down into one dimension on both the $x$ and $y$ axes (the short vertical and horizontal lines, respectively).\relax }}{43}{figure.caption.21}\protected@file@percent }
\newlabel{fig:pca-scatter}{{18}{43}{100 randomly-generated points in 2D space, showing potential projections of these points down into one dimension on both the $x$ and $y$ axes (the short vertical and horizontal lines, respectively).\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces The same data as plotted in Figure \ref {fig:pca-scatter}, but transformed via PCA so that the horizontal axis represents the direction of greatest variance (the First Principal Component) while the vertical axis represents the direction of second-greatest variance (the Second Principal Component).\relax }}{44}{figure.caption.22}\protected@file@percent }
\newlabel{fig:pca-scatter-transformed}{{19}{44}{The same data as plotted in Figure \ref {fig:pca-scatter}, but transformed via PCA so that the horizontal axis represents the direction of greatest variance (the First Principal Component) while the vertical axis represents the direction of second-greatest variance (the Second Principal Component).\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces A two-dimensional embedding space trained on the WPA Slave Narratives corpus, where we draw solid arrows connecting points for key racial terms (``white'' and ``black'') and for terms denoting status within the slave system (``slave'' and ``master''), along with a dashed arrow connecting points for gendered terms (``man'' and ``woman'').\relax }}{46}{figure.caption.23}\protected@file@percent }
\newlabel{fig:wpa-embeddings}{{20}{46}{A two-dimensional embedding space trained on the WPA Slave Narratives corpus, where we draw solid arrows connecting points for key racial terms (``white'' and ``black'') and for terms denoting status within the slave system (``slave'' and ``master''), along with a dashed arrow connecting points for gendered terms (``man'' and ``woman'').\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces The same points displayed in Figure \ref {fig:wpa-embeddings}, but transformed so that the horizontal axis represents the white-to-black direction within the space ($\texttt  {white} \bowtie  \texttt  {master}$ on the left, $\texttt  {black} \bowtie  \texttt  {slave}$ on the right), and the vertical represents the man-to-woman direction (\texttt  {man} below, \texttt  {woman} above).\relax }}{47}{figure.caption.24}\protected@file@percent }
\newlabel{fig:wpa-embeddings-transformed}{{21}{47}{The same points displayed in Figure \ref {fig:wpa-embeddings}, but transformed so that the horizontal axis represents the white-to-black direction within the space ($\entity {white} \bowtie \entity {master}$ on the left, $\entity {black} \bowtie \entity {slave}$ on the right), and the vertical represents the man-to-woman direction (\entity {man} below, \entity {woman} above).\relax }{figure.caption.24}{}}
\citation{welch_exploring_2020}
\abx@aux@cite{0}{welch_exploring_2020}
\abx@aux@segm{0}{0}{welch_exploring_2020}
\citation{skinner_visions_2012}
\abx@aux@cite{0}{skinner_visions_2012}
\abx@aux@segm{0}{0}{skinner_visions_2012}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Author-Specific Embedding Spaces}{48}{subsection.3.3}\protected@file@percent }
\newlabel{sec:auth-embeddings}{{3.3}{48}{Author-Specific Embedding Spaces}{subsection.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces A visualization of \texttt  {BERT}{}'s ability to model the different contexts (and thus, senses) in which words are used by different authors. In this case \texttt  {interference} falls squarely within the negative liberty (liberty as non-interference) cluster, as a term central to distinguishing negative from other forms of liberty, whereas \texttt  {absence} falls between two clusters as it can be employed in both republican (``absence of arbitrary power'') and negative-liberty (``absence of interference'') contexts.\relax }}{49}{figure.caption.25}\protected@file@percent }
\newlabel{fig:bert-author}{{22}{49}{A visualization of \BERT {}'s ability to model the different contexts (and thus, senses) in which words are used by different authors. In this case \texttt {interference} falls squarely within the negative liberty (liberty as non-interference) cluster, as a term central to distinguishing negative from other forms of liberty, whereas \texttt {absence} falls between two clusters as it can be employed in both republican (``absence of arbitrary power'') and negative-liberty (``absence of interference'') contexts.\relax }{figure.caption.25}{}}
\citation{kozlowski_geometry_2019}
\abx@aux@cite{0}{kozlowski_geometry_2019}
\abx@aux@segm{0}{0}{kozlowski_geometry_2019}
\citation{avineri_social_1968}
\abx@aux@cite{0}{avineri_social_1968}
\abx@aux@segm{0}{0}{avineri_social_1968}
\citation{lewis-beck_sage_2003}
\abx@aux@cite{0}{lewis-beck_sage_2003}
\abx@aux@segm{0}{0}{lewis-beck_sage_2003}
\citation{hlavackova-schindler_assumption_2012}
\abx@aux@cite{0}{hlavackova-schindler_assumption_2012}
\abx@aux@segm{0}{0}{hlavackova-schindler_assumption_2012}
\citation{wevers_tracking_2020}
\abx@aux@cite{0}{wevers_tracking_2020}
\abx@aux@segm{0}{0}{wevers_tracking_2020}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Discursive Fields as Embedding Clusters}{52}{subsection.3.4}\protected@file@percent }
\newlabel{sec:embedding-clusters}{{3.4}{52}{Discursive Fields as Embedding Clusters}{subsection.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces An illustration of how the logarithm (plotted in blue) ``smoothes out'' the original corpus-wide frequencies (plotted in orange), where the horizontal axis represents a word's ranking in the corpus ($n=1$ representing the most frequent word, $n=2$ the second most frequent, and so on) and the vertical axis represents the frequencies of these words, measured in both original and logarithmic units. In particular, note that the logarithmic plot decreases the magnitude of the differences between the first \textasciitilde 30 words, and then slightly magnifies the differences between the remaining \textasciitilde 70 words, relative to the original frequency plot.\relax }}{55}{figure.caption.26}\protected@file@percent }
\newlabel{fig:power-law}{{23}{55}{An illustration of how the logarithm (plotted in blue) ``smoothes out'' the original corpus-wide frequencies (plotted in orange), where the horizontal axis represents a word's ranking in the corpus ($n=1$ representing the most frequent word, $n=2$ the second most frequent, and so on) and the vertical axis represents the frequencies of these words, measured in both original and logarithmic units. In particular, note that the logarithmic plot decreases the magnitude of the differences between the first \textasciitilde 30 words, and then slightly magnifies the differences between the remaining \textasciitilde 70 words, relative to the original frequency plot.\relax }{figure.caption.26}{}}
\citation{pocock_virtue_1985}
\abx@aux@cite{0}{pocock_virtue_1985}
\abx@aux@segm{0}{0}{pocock_virtue_1985}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Synchronic and Diachronic Analysis: Understanding the \textit  {Langue}-\textit  {Parole} Distinction}{57}{subsection.3.5}\protected@file@percent }
\newlabel{sec:methods-diachronic}{{3.5}{57}{Synchronic and Diachronic Analysis: Understanding the \textit {Langue}-\textit {Parole} Distinction}{subsection.3.5}{}}
\citation{firth_papers_1957}
\abx@aux@cite{0}{firth_papers_1957}
\abx@aux@segm{0}{0}{firth_papers_1957}
\citation{mikolov_distributed_2013}
\abx@aux@cite{0}{mikolov_distributed_2013}
\abx@aux@segm{0}{0}{mikolov_distributed_2013}
\citation{reimers_sentencebert_2019}
\abx@aux@cite{0}{reimers_sentencebert_2019}
\abx@aux@segm{0}{0}{reimers_sentencebert_2019}
\citation{soni_abolitionist_2021}
\abx@aux@cite{0}{soni_abolitionist_2021}
\abx@aux@segm{0}{0}{soni_abolitionist_2021}
\citation{soni_abolitionist_2021}
\abx@aux@cite{0}{soni_abolitionist_2021}
\abx@aux@segm{0}{0}{soni_abolitionist_2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Putting it All Together: Networks of Semantic Influence}{59}{subsection.3.6}\protected@file@percent }
\newlabel{sec:sln}{{3.6}{59}{Putting it All Together: Networks of Semantic Influence}{subsection.3.6}{}}
\citation{soni_abolitionist_2021}
\abx@aux@cite{0}{soni_abolitionist_2021}
\abx@aux@segm{0}{0}{soni_abolitionist_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces A PGM where we've observed the person's action ($a = \textsf  {Go}$) but only have a probability distribution over the weather $w$.\relax }}{60}{figure.caption.27}\protected@file@percent }
\newlabel{fig:sln1}{{24}{60}{A PGM where we've observed the person's action ($a = \textsf {Go}$) but only have a probability distribution over the weather $w$.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces The situation of one-way influence, where $\mathsf  {Lead}_{a_1 \rightarrow a_2}(w) > \mathsf  {Lead}_{a_2 \rightarrow a_1}(w)$, allowing us to infer that $a_1$'s usage of $w$ before 1848 had more influence on $a_2$'s usage over time than vice-versa.\relax }}{61}{figure.caption.28}\protected@file@percent }
\newlabel{fig:onewayinfluence}{{25}{61}{The situation of one-way influence, where $\mathsf {Lead}_{a_1 \rightarrow a_2}(w) > \mathsf {Lead}_{a_2 \rightarrow a_1}(w)$, allowing us to infer that $a_1$'s usage of $w$ before 1848 had more influence on $a_2$'s usage over time than vice-versa.\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces The situation of mutual influence, where $\mathsf  {Lead}_{a_1 \rightarrow a_2}(w) = \mathsf  {Lead}_{a_2 \rightarrow a_1}(w)$, since $a_1$'s post-1848 usage of $w$ exactly matches $a_2$'s pre-1848 usage, and $a_2$'s post-1848 usage exactly matches $a_1$'s pre-1848 usage.\relax }}{62}{figure.caption.29}\protected@file@percent }
\newlabel{fig:mutualinfluence}{{26}{62}{The situation of mutual influence, where $\mathsf {Lead}_{a_1 \rightarrow a_2}(w) = \mathsf {Lead}_{a_2 \rightarrow a_1}(w)$, since $a_1$'s post-1848 usage of $w$ exactly matches $a_2$'s pre-1848 usage, and $a_2$'s post-1848 usage exactly matches $a_1$'s pre-1848 usage.\relax }{figure.caption.29}{}}
\citation{soni_abolitionist_2021}
\abx@aux@cite{0}{soni_abolitionist_2021}
\abx@aux@segm{0}{0}{soni_abolitionist_2021}
\citation{soni_abolitionist_2021}
\abx@aux@cite{0}{soni_abolitionist_2021}
\abx@aux@segm{0}{0}{soni_abolitionist_2021}
\citation{skinner_return_1990}
\abx@aux@cite{0}{skinner_return_1990}
\abx@aux@segm{0}{0}{skinner_return_1990}
\citation{elster_case_1982}
\abx@aux@cite{0}{elster_case_1982}
\abx@aux@segm{0}{0}{elster_case_1982}
\citation{althusser_marx_1968}
\abx@aux@cite{0}{althusser_marx_1968}
\abx@aux@segm{0}{0}{althusser_marx_1968}
\citation{cohen_karl_1978}
\abx@aux@cite{0}{cohen_karl_1978}
\abx@aux@segm{0}{0}{cohen_karl_1978}
\@writefile{toc}{\contentsline {section}{\numberline {4}The Empirics of Influence: Historical Sketches}{64}{section.4}\protected@file@percent }
\newlabel{sec:empirics-of-influence}{{4}{64}{The Empirics of Influence: Historical Sketches}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Theories of Influence, Past and Present}{64}{subsection.4.1}\protected@file@percent }
\newlabel{sec:theories-of-influence}{{4.1}{64}{Theories of Influence, Past and Present}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Structure vs. Agency}{64}{subsubsection.4.1.1}\protected@file@percent }
\newlabel{sec:structure-agency}{{4.1.1}{64}{Structure vs. Agency}{subsubsection.4.1.1}{}}
\citation{giddens_central_1979}
\abx@aux@cite{0}{giddens_central_1979}
\abx@aux@segm{0}{0}{giddens_central_1979}
\citation{giddens_central_1979}
\abx@aux@cite{0}{giddens_central_1979}
\abx@aux@segm{0}{0}{giddens_central_1979}
\citation{giddens_central_1979}
\abx@aux@cite{0}{giddens_central_1979}
\abx@aux@segm{0}{0}{giddens_central_1979}
\citation{sperber_explaining_1996}
\abx@aux@cite{0}{sperber_explaining_1996}
\abx@aux@segm{0}{0}{sperber_explaining_1996}
\citation{collingwood_idea_1946}
\abx@aux@cite{0}{collingwood_idea_1946}
\abx@aux@segm{0}{0}{collingwood_idea_1946}
\citation{popper_open_1945}
\abx@aux@cite{0}{popper_open_1945}
\abx@aux@segm{0}{0}{popper_open_1945}
\citation{arendt_origins_1951}
\abx@aux@cite{0}{arendt_origins_1951}
\abx@aux@segm{0}{0}{arendt_origins_1951}
\citation{talmon_origins_1952}
\abx@aux@cite{0}{talmon_origins_1952}
\abx@aux@segm{0}{0}{talmon_origins_1952}
\citation{schlesinger_vital_1949}
\abx@aux@cite{0}{schlesinger_vital_1949}
\abx@aux@segm{0}{0}{schlesinger_vital_1949}
\citation{adorno_authoritarian_1950}
\abx@aux@cite{0}{adorno_authoritarian_1950}
\abx@aux@segm{0}{0}{adorno_authoritarian_1950}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Mapping and Evaluating the Theories}{67}{subsubsection.4.1.2}\protected@file@percent }
\newlabel{sec:mapping-theories}{{4.1.2}{67}{Mapping and Evaluating the Theories}{subsubsection.4.1.2}{}}
\citation{bayes_essay_1763}
\abx@aux@cite{0}{bayes_essay_1763}
\abx@aux@segm{0}{0}{bayes_essay_1763}
\citation{williamson_defence_2010}
\abx@aux@cite{0}{williamson_defence_2010}
\abx@aux@segm{0}{0}{williamson_defence_2010}
\citation{connolly_terms_1974}
\abx@aux@cite{0}{connolly_terms_1974}
\abx@aux@segm{0}{0}{connolly_terms_1974}
\citation{sokal_fashionable_1997}
\abx@aux@cite{0}{sokal_fashionable_1997}
\abx@aux@segm{0}{0}{sokal_fashionable_1997}
\citation{skinner_meaning_1969}
\abx@aux@cite{0}{skinner_meaning_1969}
\abx@aux@segm{0}{0}{skinner_meaning_1969}
\newlabel{bayesoptimal}{{46}{69}{}{Hfootnote.46}{}}
\citation{mcelreath_statistical_2020}
\abx@aux@cite{0}{mcelreath_statistical_2020}
\abx@aux@segm{0}{0}{mcelreath_statistical_2020}
\citation{mcelreath_statistical_2020}
\abx@aux@cite{0}{mcelreath_statistical_2020}
\abx@aux@segm{0}{0}{mcelreath_statistical_2020}
\citation{wohl_plato_1998}
\abx@aux@cite{0}{wohl_plato_1998}
\abx@aux@segm{0}{0}{wohl_plato_1998}
\citation{collingwood_idea_1946}
\abx@aux@cite{0}{collingwood_idea_1946}
\abx@aux@segm{0}{0}{collingwood_idea_1946}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}The Empirics of Influence: Historical Sketches}{72}{subsection.4.2}\protected@file@percent }
\newlabel{sec:empirics-of-influence}{{4.2}{72}{The Empirics of Influence: Historical Sketches}{subsection.4.2}{}}
\citation{bevir_logic_1999}
\abx@aux@cite{0}{bevir_logic_1999}
\abx@aux@segm{0}{0}{bevir_logic_1999}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Text-Mining Influence Claims}{73}{subsection.4.3}\protected@file@percent }
\newlabel{sec:mining-influence-claims}{{4.3}{73}{Text-Mining Influence Claims}{subsection.4.3}{}}
\citation{rawls_outline_1951}
\abx@aux@cite{0}{rawls_outline_1951}
\abx@aux@segm{0}{0}{rawls_outline_1951}
\citation{gandy_marx_1979}
\abx@aux@cite{0}{gandy_marx_1979}
\abx@aux@segm{0}{0}{gandy_marx_1979}
\citation{ma_mentorship_2020}
\abx@aux@cite{0}{ma_mentorship_2020}
\abx@aux@segm{0}{0}{ma_mentorship_2020}
\citation{wright_schoenberg_2006}
\abx@aux@cite{0}{wright_schoenberg_2006}
\abx@aux@segm{0}{0}{wright_schoenberg_2006}
\citation{dussel_unknown_2002}
\abx@aux@cite{0}{dussel_unknown_2002}
\abx@aux@segm{0}{0}{dussel_unknown_2002}
\citation{levine_divergent_2006}
\abx@aux@cite{0}{levine_divergent_2006}
\abx@aux@segm{0}{0}{levine_divergent_2006}
\citation{morton_thunder_1990}
\abx@aux@cite{0}{morton_thunder_1990}
\abx@aux@segm{0}{0}{morton_thunder_1990}
\citation{toews_hegelianism_1985}
\abx@aux@cite{0}{toews_hegelianism_1985}
\abx@aux@segm{0}{0}{toews_hegelianism_1985}
\citation{ash_unsupervised_2020}
\abx@aux@cite{0}{ash_unsupervised_2020}
\abx@aux@segm{0}{0}{ash_unsupervised_2020}
\citation{harsanyi_cardinal_1953}
\abx@aux@cite{0}{harsanyi_cardinal_1953}
\abx@aux@segm{0}{0}{harsanyi_cardinal_1953}
\citation{roemer_theories_1996}
\abx@aux@cite{0}{roemer_theories_1996}
\abx@aux@segm{0}{0}{roemer_theories_1996}
\citation{morton_thunder_1990}
\abx@aux@cite{0}{morton_thunder_1990}
\abx@aux@segm{0}{0}{morton_thunder_1990}
\citation{barron_individuals_2018}
\abx@aux@cite{0}{barron_individuals_2018}
\abx@aux@segm{0}{0}{barron_individuals_2018}
\citation{gerow_measuring_2018}
\abx@aux@cite{0}{gerow_measuring_2018}
\abx@aux@segm{0}{0}{gerow_measuring_2018}
\citation{tilly_contentious_2008}
\abx@aux@cite{0}{tilly_contentious_2008}
\abx@aux@segm{0}{0}{tilly_contentious_2008}
\citation{kulkarni_statistically_2015}
\abx@aux@cite{0}{kulkarni_statistically_2015}
\abx@aux@segm{0}{0}{kulkarni_statistically_2015}
\citation{hudson_double_1992}
\abx@aux@cite{0}{hudson_double_1992}
\abx@aux@segm{0}{0}{hudson_double_1992}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}The Point is to Change It: Theoretical Innovation and Political Practice in the History of Marxism}{78}{subsection.4.4}\protected@file@percent }
\newlabel{sec:history-of-marxism}{{4.4}{78}{The Point is to Change It: Theoretical Innovation and Political Practice in the History of Marxism}{subsection.4.4}{}}
\citation{mclellan_marxism_2007}
\abx@aux@cite{0}{mclellan_marxism_2007}
\abx@aux@segm{0}{0}{mclellan_marxism_2007}
\citation{barron_individuals_2018}
\abx@aux@cite{0}{barron_individuals_2018}
\abx@aux@segm{0}{0}{barron_individuals_2018}
\citation{gerow_measuring_2018}
\abx@aux@cite{0}{gerow_measuring_2018}
\abx@aux@segm{0}{0}{gerow_measuring_2018}
\citation{skinner_meaning_1969}
\abx@aux@cite{0}{skinner_meaning_1969}
\abx@aux@segm{0}{0}{skinner_meaning_1969}
\newlabel{fig:novelty-resonance-marxism}{{27a}{81}{Novelty and resonance scores for each text in our corpus of influential Marxist texts.\relax }{figure.caption.30}{}}
\newlabel{sub@fig:novelty-resonance-marxism}{{a}{81}{Novelty and resonance scores for each text in our corpus of influential Marxist texts.\relax }{figure.caption.30}{}}
\newlabel{fig:transience-novelty-marxism}{{27b}{81}{Transience and novelty scores for each text in our corpus of influential Marxist texts.\relax }{figure.caption.30}{}}
\newlabel{sub@fig:transience-novelty-marxism}{{b}{81}{Transience and novelty scores for each text in our corpus of influential Marxist texts.\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{81}{section.5}\protected@file@percent }
\newlabel{sec:conclusion}{{5}{81}{Conclusion}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Probabilistic Graphical Models in Political Theory}{83}{appendix.A}\protected@file@percent }
\newlabel{sec:pgms}{{A}{83}{Probabilistic Graphical Models in Political Theory}{appendix.A}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}General Graphical Models}{83}{subsection.A.1}\protected@file@percent }
\newlabel{sec:gms}{{A.1}{83}{General Graphical Models}{subsection.A.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces A graphical model illustrating the initial decomposition which a historian of the French Revolution might perform to make their analysis more tractable: three nodes representing three historical entities---the Nobility, the Clergy, and the Third Estate---and edges representing the interrelationships between each pair of entities.\relax }}{84}{figure.caption.31}\protected@file@percent }
\newlabel{fig:fr-pgm-mainstream}{{28}{84}{A graphical model illustrating the initial decomposition which a historian of the French Revolution might perform to make their analysis more tractable: three nodes representing three historical entities---the Nobility, the Clergy, and the Third Estate---and edges representing the interrelationships between each pair of entities.\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces A graphical model illustrating the initial decomposition which a Marxist historian of the French Revolution might perform to make their analysis more tractable: three nodes representing three historical entities---the Bourgeoisie, the Proletariat, and the Peasantry---and edges representing the interrelationships between each pair of entities.\relax }}{85}{figure.caption.32}\protected@file@percent }
\newlabel{fig:fr-pgm-marxist}{{29}{85}{A graphical model illustrating the initial decomposition which a Marxist historian of the French Revolution might perform to make their analysis more tractable: three nodes representing three historical entities---the Bourgeoisie, the Proletariat, and the Peasantry---and edges representing the interrelationships between each pair of entities.\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces A graphical model illustrating the initial decomposition which a ``Great Man'' theorist might perform to make their analysis of the French Revolution more tractable, with nodes for prominent individuals and edges between individuals who are known to have interacted.\relax }}{85}{figure.caption.33}\protected@file@percent }
\newlabel{fig:fr-pgm-greatman}{{30}{85}{A graphical model illustrating the initial decomposition which a ``Great Man'' theorist might perform to make their analysis of the French Revolution more tractable, with nodes for prominent individuals and edges between individuals who are known to have interacted.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}The Role of Probability}{86}{subsection.A.2}\protected@file@percent }
\newlabel{sec:probability}{{A.2}{86}{The Role of Probability}{subsection.A.2}{}}
\citation{gallagher_anchored_2017}
\abx@aux@cite{0}{gallagher_anchored_2017}
\abx@aux@segm{0}{0}{gallagher_anchored_2017}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Randomly-chosen words from Wikipedia articles on Thomas Hobbes and Karl Marx, versus randomly-chosen words from across all Wikipedia articles\relax }}{88}{table.caption.34}\protected@file@percent }
\newlabel{tab:hobbes-wiki}{{3}{88}{Randomly-chosen words from Wikipedia articles on Thomas Hobbes and Karl Marx, versus randomly-chosen words from across all Wikipedia articles\relax }{table.caption.34}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Data-Generating Process for a Text Corpus\relax }}{89}{algorithm.1}\protected@file@percent }
\newlabel{alg:text-corpus}{{1}{89}{Data-Generating Process for a Text Corpus\relax }{algorithm.1}{}}
\citation{blei_introduction_2012}
\abx@aux@cite{0}{blei_introduction_2012}
\abx@aux@segm{0}{0}{blei_introduction_2012}
\citation{blei_introduction_2012}
\abx@aux@cite{0}{blei_introduction_2012}
\abx@aux@segm{0}{0}{blei_introduction_2012}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces From \blx@tocontentsinit {0}\cite {blei_introduction_2012}, p. 3\relax }}{91}{figure.caption.35}\protected@file@percent }
\newlabel{fig:my_label}{{31}{91}{From \cite {blei_introduction_2012}, p. 3\relax }{figure.caption.35}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Data-Generating Process for Evening Plans\relax }}{91}{algorithm.2}\protected@file@percent }
\newlabel{alg:party-weather}{{2}{91}{Data-Generating Process for Evening Plans\relax }{algorithm.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces A basic PGM, representing the relationship between $w$, the weather, and $a$, the subsequent action of a person deciding whether to go out or stay in for the night.\relax }}{92}{figure.caption.36}\protected@file@percent }
\newlabel{fig:pgm1}{{32}{92}{A basic PGM, representing the relationship between $w$, the weather, and $a$, the subsequent action of a person deciding whether to go out or stay in for the night.\relax }{figure.caption.36}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces The Conditional Probability Table for the PGM shown in Figure \ref {fig:pgm1}.\relax }}{92}{table.caption.37}\protected@file@percent }
\newlabel{tab:cpt1}{{4}{92}{The Conditional Probability Table for the PGM shown in Figure \ref {fig:pgm1}.\relax }{table.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces A PGM representing the same situation as in Figure \ref {fig:pgm1}, except that the node for variable $a$ is now shaded, indicating a situation where we have observed the person's action ($a = \textsf  {Go Out}$) but still only have a probability distribution over the weather $w$.\relax }}{92}{figure.caption.38}\protected@file@percent }
\newlabel{fig:pgm2}{{33}{92}{A PGM representing the same situation as in Figure \ref {fig:pgm1}, except that the node for variable $a$ is now shaded, indicating a situation where we have observed the person's action ($a = \textsf {Go Out}$) but still only have a probability distribution over the weather $w$.\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Topic Models}{93}{subsection.A.3}\protected@file@percent }
\newlabel{sec:topic-models}{{A.3}{93}{Topic Models}{subsection.A.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces A first attempt at a PGM representing the data-generating process for an observed word $w_{d,i}$, the $i$th word in document $d$, within a text.\relax }}{94}{figure.caption.39}\protected@file@percent }
\newlabel{fig:pgm-word-simple}{{34}{94}{A first attempt at a PGM representing the data-generating process for an observed word $w_{d,i}$, the $i$th word in document $d$, within a text.\relax }{figure.caption.39}{}}
\citation{rude_crowd_1959}
\abx@aux@cite{0}{rude_crowd_1959}
\abx@aux@segm{0}{0}{rude_crowd_1959}
\citation{rude_crowd_1964}
\abx@aux@cite{0}{rude_crowd_1964}
\abx@aux@segm{0}{0}{rude_crowd_1964}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces A PGM representing the \textsf  {Specify-Documents} sub-process, in which the author specifies a topic distribution $\theta _d$.\relax }}{95}{figure.caption.40}\protected@file@percent }
\newlabel{fig:pgm-specify-documents}{{35}{95}{A PGM representing the \textsf {Specify-Documents} sub-process, in which the author specifies a topic distribution $\theta _d$.\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces A PGM representing the \textsf  {Specify-Documents} sub-process, using plate notation to condense the repetition in Figure \ref {fig:pgm-specify-documents}.\relax }}{95}{figure.caption.41}\protected@file@percent }
\newlabel{fig:pgm-specify-documents-plate}{{36}{95}{A PGM representing the \textsf {Specify-Documents} sub-process, using plate notation to condense the repetition in Figure \ref {fig:pgm-specify-documents}.\relax }{figure.caption.41}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces An example Conditional Probability Table for the \textsf  {Specify-Documents} PGM shown in Figures \ref {fig:pgm-specify-documents} and \ref {fig:pgm-specify-documents-plate}.\relax }}{95}{table.caption.42}\protected@file@percent }
\newlabel{tab:cpt-specify-documents}{{5}{95}{An example Conditional Probability Table for the \textsf {Specify-Documents} PGM shown in Figures \ref {fig:pgm-specify-documents} and \ref {fig:pgm-specify-documents-plate}.\relax }{table.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces A PGM representing the \textsf  {Specify-Topics} sub-process, in which an author specifies a word importance score $p_t(w)$ for each word $w$ and topic $t$.\relax }}{96}{figure.caption.43}\protected@file@percent }
\newlabel{fig:pgm-specify-topics}{{37}{96}{A PGM representing the \textsf {Specify-Topics} sub-process, in which an author specifies a word importance score $p_t(w)$ for each word $w$ and topic $t$.\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces A PGM representing the \textsf  {Specify-Topics} sub-process, using plate notation to condense the repetition in Figure \ref {fig:pgm-specify-topics}.\relax }}{96}{figure.caption.44}\protected@file@percent }
\newlabel{fig:pgm-specify-topics-plate}{{38}{96}{A PGM representing the \textsf {Specify-Topics} sub-process, using plate notation to condense the repetition in Figure \ref {fig:pgm-specify-topics}.\relax }{figure.caption.44}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces An example Conditional Probability Table for the \textsf  {Specify-Topics} PGM shown in Figure \ref {fig:pgm-specify-topics}.\relax }}{96}{table.caption.45}\protected@file@percent }
\newlabel{tab:cpt-specify-topics}{{6}{96}{An example Conditional Probability Table for the \textsf {Specify-Topics} PGM shown in Figure \ref {fig:pgm-specify-topics}.\relax }{table.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces The complete PGM representing the data-generating process for an observed word $w_{d,i}$, with the \textsf  {Specify-Documents} and \textsf  {Specify-Topics} sub-processes incorporated explicitly.\relax }}{96}{figure.caption.46}\protected@file@percent }
\newlabel{fig:pgm-full}{{39}{96}{The complete PGM representing the data-generating process for an observed word $w_{d,i}$, with the \textsf {Specify-Documents} and \textsf {Specify-Topics} sub-processes incorporated explicitly.\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces A PGM representing the fusion of several individual models of French Revolutionary entities, to explain the observed outcomes in the revolutionary Legislative Assembly.\relax }}{97}{figure.caption.47}\protected@file@percent }
\newlabel{fig:pgm-crowd}{{40}{97}{A PGM representing the fusion of several individual models of French Revolutionary entities, to explain the observed outcomes in the revolutionary Legislative Assembly.\relax }{figure.caption.47}{}}
\@writefile{toc}{\contentsline {chapter}{References}{98}{figure.caption.47}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{A45F1FC92C4B152F9BEAAE407C874F4A}
\abx@aux@defaultrefcontext{0}{adorno_authoritarian_1950}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{althusser_marx_1968}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{arendt_origins_1951}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{ash_ideas_2017}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{ash_unsupervised_2020}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{ashcraft_locke_1986}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{austin_how_1962}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{avineri_social_1968}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{barron_individuals_2018}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{bayes_essay_1763}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{beltagy_longformer_2020}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{bevir_are_1994}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{bevir_logic_1999}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{blei_introduction_2012}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{chi_finding_2020}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{cohen_karl_1978}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{collingwood_idea_1946}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{comrie_languages_1981}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{connolly_terms_1974}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{darnton_revolution_1989}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{devlin_bert_2019}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{dokmanic_euclidean_2015}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{dummett_frege_1973}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{dussel_unknown_2002}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{elster_case_1982}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{feng_languageagnostic_2022}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{feuer_north_1963}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{firth_papers_1957}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{gallagher_anchored_2017}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{gandy_marx_1979}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{gerow_measuring_2018}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{giddens_central_1979}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{goodman_republic_1996}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{gourevitch_slavery_2015}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{gregoire_geste_1948}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{harsanyi_cardinal_1953}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{heffernan_bitext_2022}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{hlavackova-schindler_assumption_2012}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{hudson_double_1992}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{jacobs_quantifying_2021}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{jakobson_child_1941}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{jakobson_linguistics_1957}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{jakobson_linguistics_1960}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{jurafsky_language_2014}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{kozlowski_geometry_2019}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{kulkarni_statistically_2015}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{lazaridou_this_2014}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{levine_divergent_2006}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{lewis-beck_sage_2003}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{london_reimagining_2016}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{ma_mentorship_2020}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{marx_herr_1860}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{mcelreath_statistical_2020}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{mclellan_marxism_2007}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{mikolov_distributed_2013}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{morton_thunder_1990}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{mosteller_inference_1964}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{parekh_history_1973}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{plamenatz_man_1963}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{pocock_virtue_1985}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{pocock_political_2009}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{pocock_machiavellian_1975}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{popper_open_1945}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{prawer_karl_1976}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{quine_word_1960}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{rawls_outline_1951}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{reimers_sentencebert_2019}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{rheault_word_2020}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{roemer_theories_1996}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{rose_reading_1978}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{rude_crowd_1959}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{rude_crowd_1964}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{saussure_course_1916}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{schlesinger_vital_1949}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{scott_schools_2001}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{shapiro_selective_1987}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{skinner_meaning_1969}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{skinner_foundations_1978a}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{skinner_foundations_1978b}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{skinner_return_1990}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{skinner_liberty_1998}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{skinner_hobbes_2008}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{skinner_visions_2012}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{sokal_fashionable_1997}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{soni_abolitionist_2021}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{sperber_explaining_1996}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{strauss_what_1959}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{talmon_origins_1952}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{tilly_contentious_2008}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{toews_hegelianism_1985}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{tully_meaning_1988}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{vendruscolo_recovery_1997}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{welch_exploring_2020}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{wevers_tracking_2020}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{wevers_digital_2020}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{williamson_defence_2010}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{wittgenstein_tractatus_1921}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{wittgenstein_philosophical_1953}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{wohl_plato_1998}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{wood_citizens_2008}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{wright_schoenberg_2006}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{yang_languageagnostic_2020}{nyvt/global//global/global}
\abx@aux@defaultrefcontext{0}{yetman_background_1967}{nyvt/global//global/global}
\abx@aux@defaultlabelprefix{0}{adorno_authoritarian_1950}{}
\abx@aux@defaultlabelprefix{0}{althusser_marx_1968}{}
\abx@aux@defaultlabelprefix{0}{arendt_origins_1951}{}
\abx@aux@defaultlabelprefix{0}{ash_ideas_2017}{}
\abx@aux@defaultlabelprefix{0}{ash_unsupervised_2020}{}
\abx@aux@defaultlabelprefix{0}{ashcraft_locke_1986}{}
\abx@aux@defaultlabelprefix{0}{austin_how_1962}{}
\abx@aux@defaultlabelprefix{0}{avineri_social_1968}{}
\abx@aux@defaultlabelprefix{0}{barron_individuals_2018}{}
\abx@aux@defaultlabelprefix{0}{bayes_essay_1763}{}
\abx@aux@defaultlabelprefix{0}{beltagy_longformer_2020}{}
\abx@aux@defaultlabelprefix{0}{bevir_are_1994}{}
\abx@aux@defaultlabelprefix{0}{bevir_logic_1999}{}
\abx@aux@defaultlabelprefix{0}{blei_introduction_2012}{}
\abx@aux@defaultlabelprefix{0}{chi_finding_2020}{}
\abx@aux@defaultlabelprefix{0}{cohen_karl_1978}{}
\abx@aux@defaultlabelprefix{0}{collingwood_idea_1946}{}
\abx@aux@defaultlabelprefix{0}{comrie_languages_1981}{}
\abx@aux@defaultlabelprefix{0}{connolly_terms_1974}{}
\abx@aux@defaultlabelprefix{0}{darnton_revolution_1989}{}
\abx@aux@defaultlabelprefix{0}{devlin_bert_2019}{}
\abx@aux@defaultlabelprefix{0}{dokmanic_euclidean_2015}{}
\abx@aux@defaultlabelprefix{0}{dummett_frege_1973}{}
\abx@aux@defaultlabelprefix{0}{dussel_unknown_2002}{}
\abx@aux@defaultlabelprefix{0}{elster_case_1982}{}
\abx@aux@defaultlabelprefix{0}{feng_languageagnostic_2022}{}
\abx@aux@defaultlabelprefix{0}{feuer_north_1963}{}
\abx@aux@defaultlabelprefix{0}{firth_papers_1957}{}
\abx@aux@defaultlabelprefix{0}{gallagher_anchored_2017}{}
\abx@aux@defaultlabelprefix{0}{gandy_marx_1979}{}
\abx@aux@defaultlabelprefix{0}{gerow_measuring_2018}{}
\abx@aux@defaultlabelprefix{0}{giddens_central_1979}{}
\abx@aux@defaultlabelprefix{0}{goodman_republic_1996}{}
\abx@aux@defaultlabelprefix{0}{gourevitch_slavery_2015}{}
\abx@aux@defaultlabelprefix{0}{gregoire_geste_1948}{}
\abx@aux@defaultlabelprefix{0}{harsanyi_cardinal_1953}{}
\abx@aux@defaultlabelprefix{0}{heffernan_bitext_2022}{}
\abx@aux@defaultlabelprefix{0}{hlavackova-schindler_assumption_2012}{}
\abx@aux@defaultlabelprefix{0}{hudson_double_1992}{}
\abx@aux@defaultlabelprefix{0}{jacobs_quantifying_2021}{}
\abx@aux@defaultlabelprefix{0}{jakobson_child_1941}{}
\abx@aux@defaultlabelprefix{0}{jakobson_linguistics_1957}{}
\abx@aux@defaultlabelprefix{0}{jakobson_linguistics_1960}{}
\abx@aux@defaultlabelprefix{0}{jurafsky_language_2014}{}
\abx@aux@defaultlabelprefix{0}{kozlowski_geometry_2019}{}
\abx@aux@defaultlabelprefix{0}{kulkarni_statistically_2015}{}
\abx@aux@defaultlabelprefix{0}{lazaridou_this_2014}{}
\abx@aux@defaultlabelprefix{0}{levine_divergent_2006}{}
\abx@aux@defaultlabelprefix{0}{lewis-beck_sage_2003}{}
\abx@aux@defaultlabelprefix{0}{london_reimagining_2016}{}
\abx@aux@defaultlabelprefix{0}{ma_mentorship_2020}{}
\abx@aux@defaultlabelprefix{0}{marx_herr_1860}{}
\abx@aux@defaultlabelprefix{0}{mcelreath_statistical_2020}{}
\abx@aux@defaultlabelprefix{0}{mclellan_marxism_2007}{}
\abx@aux@defaultlabelprefix{0}{mikolov_distributed_2013}{}
\abx@aux@defaultlabelprefix{0}{morton_thunder_1990}{}
\abx@aux@defaultlabelprefix{0}{mosteller_inference_1964}{}
\abx@aux@defaultlabelprefix{0}{parekh_history_1973}{}
\abx@aux@defaultlabelprefix{0}{plamenatz_man_1963}{}
\abx@aux@defaultlabelprefix{0}{pocock_virtue_1985}{}
\abx@aux@defaultlabelprefix{0}{pocock_political_2009}{}
\abx@aux@defaultlabelprefix{0}{pocock_machiavellian_1975}{}
\abx@aux@defaultlabelprefix{0}{popper_open_1945}{}
\abx@aux@defaultlabelprefix{0}{prawer_karl_1976}{}
\abx@aux@defaultlabelprefix{0}{quine_word_1960}{}
\abx@aux@defaultlabelprefix{0}{rawls_outline_1951}{}
\abx@aux@defaultlabelprefix{0}{reimers_sentencebert_2019}{}
\abx@aux@defaultlabelprefix{0}{rheault_word_2020}{}
\abx@aux@defaultlabelprefix{0}{roemer_theories_1996}{}
\abx@aux@defaultlabelprefix{0}{rose_reading_1978}{}
\abx@aux@defaultlabelprefix{0}{rude_crowd_1959}{}
\abx@aux@defaultlabelprefix{0}{rude_crowd_1964}{}
\abx@aux@defaultlabelprefix{0}{saussure_course_1916}{}
\abx@aux@defaultlabelprefix{0}{schlesinger_vital_1949}{}
\abx@aux@defaultlabelprefix{0}{scott_schools_2001}{}
\abx@aux@defaultlabelprefix{0}{shapiro_selective_1987}{}
\abx@aux@defaultlabelprefix{0}{skinner_meaning_1969}{}
\abx@aux@defaultlabelprefix{0}{skinner_foundations_1978a}{}
\abx@aux@defaultlabelprefix{0}{skinner_foundations_1978b}{}
\abx@aux@defaultlabelprefix{0}{skinner_return_1990}{}
\abx@aux@defaultlabelprefix{0}{skinner_liberty_1998}{}
\abx@aux@defaultlabelprefix{0}{skinner_hobbes_2008}{}
\abx@aux@defaultlabelprefix{0}{skinner_visions_2012}{}
\abx@aux@defaultlabelprefix{0}{sokal_fashionable_1997}{}
\abx@aux@defaultlabelprefix{0}{soni_abolitionist_2021}{}
\abx@aux@defaultlabelprefix{0}{sperber_explaining_1996}{}
\abx@aux@defaultlabelprefix{0}{strauss_what_1959}{}
\abx@aux@defaultlabelprefix{0}{talmon_origins_1952}{}
\abx@aux@defaultlabelprefix{0}{tilly_contentious_2008}{}
\abx@aux@defaultlabelprefix{0}{toews_hegelianism_1985}{}
\abx@aux@defaultlabelprefix{0}{tully_meaning_1988}{}
\abx@aux@defaultlabelprefix{0}{vendruscolo_recovery_1997}{}
\abx@aux@defaultlabelprefix{0}{welch_exploring_2020}{}
\abx@aux@defaultlabelprefix{0}{wevers_tracking_2020}{}
\abx@aux@defaultlabelprefix{0}{wevers_digital_2020}{}
\abx@aux@defaultlabelprefix{0}{williamson_defence_2010}{}
\abx@aux@defaultlabelprefix{0}{wittgenstein_tractatus_1921}{}
\abx@aux@defaultlabelprefix{0}{wittgenstein_philosophical_1953}{}
\abx@aux@defaultlabelprefix{0}{wohl_plato_1998}{}
\abx@aux@defaultlabelprefix{0}{wood_citizens_2008}{}
\abx@aux@defaultlabelprefix{0}{wright_schoenberg_2006}{}
\abx@aux@defaultlabelprefix{0}{yang_languageagnostic_2020}{}
\abx@aux@defaultlabelprefix{0}{yetman_background_1967}{}
\gdef\svg@ink@ver@settings{{\m@ne }{inkscape}{1}}
\gdef \@abspage@last{104}
